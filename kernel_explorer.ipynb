{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['target'].value_counts().plot(kind='bar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid = [col for col in df if (df[col].nunique()==1)]\n",
    "df = df.drop(invalid,axis=1)\n",
    "characters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "string_total = [col for col in df if any (df[col].astype(str).str.lower().str.contains(('|'.join(characters))))]\n",
    "cols = df.columns.drop(strings_total)\n",
    "df[cols] = df[cols].apply(pd.to_numeric)\n",
    "categorical = []\n",
    "dummies = strings_total+categorical\n",
    "df_ready = pd.get_dummies(df, drop_first=True, columns=dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_ready.loc[:,df_ready.columns != 'target']\n",
    "y = df_ready.loc[:,df_ready.columns == 'target']\n",
    "x_train, x_test, y_train, y_test = train_test_split (x, y, test_size = 0.25, random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1, create a list of the columns that need to be scaled.\n",
    "scale = list(set(df_ready.columns)-set(dummies))\n",
    "scale.remove('target')\n",
    "# Step 2, create a list of columns that don't need to be scaled.\n",
    "unscale = list(set(df_ready.columns)-set(scale))\n",
    "unscale.remove ('target')\n",
    "# Step 3, create seperate dataframes that are resp. scaled and unscaled from the test and training set.\n",
    "sc_x = StandardScaler()\n",
    "scaled_vars_train = pd.Dataframe(sc_x.fit_transform(x_train[scale]),\n",
    "                                 index=x_train.index,columns=x_train.columns)\n",
    "unscaled_vars_train = pd.Dataframe(x_train[unscale],\n",
    "                                   index=x_train,columns=x_train.columns)\n",
    "scaled_vars_test = pd.Dataframe(sc_x.fit(x_test[scale]),\n",
    "                                 index=x_test.index,columns=x_test.columns)\n",
    "unscaled_vars_test = pd.Dataframe(x_test[unscale],\n",
    "                                   index=x_test,columns=x_test.columns)\n",
    "# Step 4, merge the dataframes back together.\n",
    "x_train = scaled_vars_train.join(unscaled_vars_train, how = 'inner')\n",
    "x_test = scaled_vars_test.join(unscaled_vars_test, how = 'inner')\n",
    "# Step 5, make a copy of the x_train dataframe for indexing columns names with output later\n",
    "x_df = x_train.copy()\n",
    "# Step 6, keep only the numpy arrays for ML apllications:\n",
    "x_train = x_train.copy().values\n",
    "y_train = y_train.copy().values\n",
    "x_test = x_test.copy().values\n",
    "y_test = y_test.copy().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Gaussian and Radial kernel in Support Vector Machines via Grid Search and assess Linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel = 'linear', random_state =34)\n",
    "parameters = [{'c': [1, 10, 100, 1000], 'kernel':['linear']},\n",
    "              {'c': [1, 10, 100, 1000], 'kernel':['rbf'], 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,\n",
    "                                                                    0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'accuracy', cv=10, n_jobs= -1)\n",
    "grid_search = grid_search.fit(x_train,y_train.ravel())\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_accuracy)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all model if possible in a consistent manner:\n",
    "report_accuracy = cross_val_score (estimator = model,X=x_train,Y=y_train.ravel(),cv=10)\n",
    "print(round((report_accuracy.mean()*100)).astype('str')+'%'+',This is the mean accuracy of 10 model evaluations.')\n",
    "print(round(report_accuracy.std()).astype('str')+'%'+' ,This means that on average'+\n",
    "     ', the differences of the 10 model accuracy estimation of the model is'+ \n",
    "      round(report_accuracy.std()).astype('str')+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
