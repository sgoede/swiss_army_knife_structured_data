{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset\n",
    "wget -p https://github.com/otacke/udacity-machine-learning-engineer/blob/master/submissions/capstone_project/data/Video_Games_Sales_as_at_22_Dec_2016.csv\n",
    "\n",
    "## Move it to the proper location:\n",
    "~/Downloads/github.com/otacke/udacity-machine-learning-engineer/blob/master/submissions/capstone_project/data$ mv Video_Games_Sales_as_at_22_Dec_2016.csv ~/anaconda3/envs/glmnet/input\n",
    "\n",
    "## Description of the dataset:\n",
    "https://www.kaggle.com/gregorut/videogamesales\n",
    "## Great example\n",
    "https://www.kaggle.com/ignacioch/predicting-vg-hits-1-million-sales-with-lr-rfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys,scipy,joblib,importlib,pprint,matplotlib.pyplot as plt,warnings,glmnet_python,pandas as pd \\\n",
    ",numpy as np,seaborn as sns, random\n",
    "from glmnet import glmnet; from glmnetPlot import glmnetPlot\n",
    "from glmnetPrint import glmnetPrint; from glmnetCoef import glmnetCoef; from glmnetPredict import glmnetPredict\n",
    "from cvglmnet import cvglmnet; from cvglmnetCoef import cvglmnetCoef\n",
    "from cvglmnetPredict import cvglmnetPredict;from cvglmnetPlot import cvglmnetPlot; \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn import metrics\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset as a dataframe\n",
    "\n",
    "## use meaningfull names for your dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "videogames_2016 = pd.read_csv('~/anaconda3/envs/glmnet/input/Video_Games_Sales_as_at_22_Dec_2016.csv', encoding=\"utf-8\")\n",
    "videogames_2016.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since total sales is accumilated by the splitted sales columns in the dataframe, first it is best to remove these,\n",
    "# the name of the game can be seen as a unique identifier \n",
    "#, (although a marketing startegy can be build on a plumber an his brother(s)) for now it's dropped from the frame\n",
    "# and to rename the Global_Sales column to target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns from the dataframe that have no added value\n",
    "cols=['Name','NA_Sales','EU_Sales','JP_Sales','Other_Sales']\n",
    "videogames_2016=videogames_2016.drop(cols,axis=1)\n",
    "videogames_2016=videogames_2016.rename(index=str,columns={'Global_Sales':'target'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for missing values in dataframe and handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the check for missing values in this dataframe returns:'+str(videogames_2016.isnull().values.any()))\n",
    "print('in this dataframe a total of '+str(videogames_2016.isnull().sum().sum())+' NaN values are present')\n",
    "print('in the table below the numbers of NaN values per column are listed ''\\n'+str(videogames_2016.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since this is a tutorial on GLMNET, let's drop all the rows that have any NaN from the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videogames_2016=videogames_2016.dropna()\n",
    "print('the check for missing values in this dataframe returns:'+str(videogames_2016.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in videogames_2016.columns:\n",
    "    if videogames_2016[col].dtype==np.float64 or videogames_2016[col].dtype==np.int64:\n",
    "        print('column '+col+' is numeric type')\n",
    "    else:\n",
    "        print('column '+col+' is string type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling: correct data type of column user_score to be of type numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before the type conversion, the data type of User_Score = '+str(videogames_2016['User_Score'].dtype))\n",
    "videogames_2016['User_Score']=videogames_2016['User_Score'].astype('float64')\n",
    "print('after the type conversion, the data type of User_Score = '+str(videogames_2016['User_Score'].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( videogames_2016.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=['Platform','Genre','Publisher','Developer','Rating']\n",
    "videogames_2016_d=pd.get_dummies(videogames_2016,columns=dummies,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videogames_2016_d.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train- and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=videogames_2016_d.loc[:,videogames_2016_d.columns != 'target']\n",
    "y=videogames_2016_d.loc[:,videogames_2016_d.columns == 'target']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.4,random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=list(set(videogames_2016.columns)-set(dummies))\n",
    "scale.remove('target')\n",
    "unscale=list(set(videogames_2016_d)-set(scale))\n",
    "unscale.remove('target')\n",
    "sc_x=StandardScaler()\n",
    "scaled_vars_train=pd.DataFrame(sc_x.fit_transform(x_train[scale]),index=x_train.index,columns=x_train[scale].columns)\n",
    "unscaled_vars_train=pd.DataFrame(x_train[unscale],index=x_train.index,columns=x_train[unscale].columns)\n",
    "x_train=scaled_vars_train.join(unscaled_vars_train,how='inner')\n",
    "scaled_vars_test=pd.DataFrame(sc_x.transform(x_test[scale]),index=x_test.index,columns=x_test[scale].columns)\n",
    "unscaled_vars_test=pd.DataFrame(x_test[unscale],index=x_test.index,columns=x_test[unscale].columns)\n",
    "x_test=scaled_vars_test.join(unscaled_vars_test,how='inner')\n",
    "x_df=x_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating numpy arrays for model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.copy().values\n",
    "y_train=y_train.copy().values\n",
    "x_test=x_test.copy().values\n",
    "y_test=y_test.copy().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model: Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression().fit(x_train, y_train)\n",
    "r_sq = lin_reg.score(x_train,y_train)\n",
    "r_sq_t = lin_reg.score(x_test,y_test)\n",
    "y_pred = lin_reg.predict(x_test)\n",
    "print('Coefficient of determination: Training Set',r_sq)\n",
    "print('Coefficient of determination: Test Set',r_sq_t)\n",
    "print('Root Mean Squared Error of baseline model on test set:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building reguralized regression models using GLMNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, the default level of alpha (1.0) is used. This means LASSO regression is performed. There are 100 different levels of Lambda tries out, that will eventually set all coefficients from the original Ordinairy Least Squares (OLS, or the benchmark model) to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit=glmnet(x=x_train,y=y_train)\n",
    "plt.figure(figsize=(16,22))\n",
    "plt.rcParams.update({'font.size':22})\n",
    "glmnetPlot(fit,xvar='lambda',label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a standard cross-validated GLMNET. (cross-validated LASSO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvfit=cvglmnet(x=x_train,y=y_train,family='gaussian',ptype='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "plt.figure(figsize=(16,12))\n",
    "cvglmnetPlot(cvfit)\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above. what level of Lambda has been used to generate the absolute lowest cross-validated error? This is the left dashed blue line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_min=cvfit['lambda_min']\n",
    "print(f'Out of the cross-validated GLMNET procedure the absolute lowest error is obtained with Lambda:{lambda_min}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_1se=cvfit['lambda_1se']\n",
    "print(f'''Out of the cross-validated GLMNET procedure the lowest error within 1 standard error is obtained with\n",
    "      Lambda:{lambda_1se}.This value yields the most parsimonious model.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using grid search on cross-validated GLMNET procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that GLMNET does NOT search for values of alpha. A specific value should be supplied, else alpha=1.0 is the used default. If users want to cross-validate alpha also, they should call cv.glmnet with a pre-computed vector: foldid and use this in seperate calls to cv.glmnet with different levels of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "foldid=scipy.random.choice(10,size=y_train.shape[0],replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=dict([(f'glm{alpha}',cvglmnet(x=x_train,\n",
    "                                    y=y_train,\n",
    "                                    foldid=foldid,\n",
    "                                    family='gaussian',\n",
    "                                    ptype='mse',\n",
    "                                    alpha=alpha,\n",
    "                                    parallel=True))for alpha in alpha])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training set performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 3 most distinctive levels of alpha, plot all the levels of lambda (100), with the associated error rate from the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(scipy.log(models['glm0.0']['lambdau']),models['glm0.0']['cvm'],'r')\n",
    "plt.plot(scipy.log(models['glm0.5']['lambdau']),models['glm0.5']['cvm'],'g')\n",
    "plt.plot(scipy.log(models['glm1.0']['lambdau']),models['glm1.0']['cvm'],'b')\n",
    "plt.xlabel(('log(Lambda)'))\n",
    "plt.ylabel(models['glm1.0']['name'])\n",
    "plt.legend(('alpha = 0 or RIDGE', 'alpha=0.5 or Elastic Net', 'alpha=1 or LASSO'), loc='upper left',prop={'size':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(34)\n",
    "\n",
    "predictions=dict(\n",
    "    [(model_name,\n",
    "    pd.Series(cvglmnetPredict(model,\n",
    "                             newx=x_test,\n",
    "                             s='lambda_1se',\n",
    "                             ptype='link')[:,0],\n",
    "             name='Prediction'))\n",
    "    for model_name, model in models.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(34)\n",
    "\n",
    "predictions=dict(\n",
    "    [(model_name,\n",
    "    cvglmnetPredict(model,\n",
    "                             newx=x_test,\n",
    "                             s='lambda_1se',\n",
    "                   ))\n",
    "    for model_name, model in models.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['glm0.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['glm0.0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = dict(\n",
    "    [(model_name, \n",
    "      mean_absolute_error(pd.Series(y_test[:,0]),predictions[model_name]))\n",
    "     for model_name in models.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = dict(\n",
    "    [(model_name, \n",
    "      sqrt(mean_squared_error(pd.Series(y_test[:,0]),predictions[model_name])))\n",
    "     for model_name in models.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[(key,RMSE) for key, RMSE in accuracies.items()], columns=['model_name','RMSE'])\\\n",
    ".plot.bar(x='model_name',y='RMSE',color='blue',figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = (min(accuracies,key=accuracies.get))\n",
    "best_RMSE = (min(accuracies.values()))\n",
    "print(f'The best model is {best_alpha} and scores a RMSE of {round(best_RMSE,2)} on the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show best model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_coeffs = cvglmnetCoef(models[best_alpha],s='lambda_min')\n",
    "intercept = best_coeffs[0][0]\n",
    "varsnames = list(x_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selected = pd.DataFrame(\n",
    "    data=list(zip(['intercept']+list(x_df.columns),[float(coeff) for coeff in best_coeffs])),\n",
    "    columns=['feature','beta'])\n",
    "pd.set_option('display.max_rows',len(model_selected))\n",
    "model_selected.reindex(model_selected.beta.abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:glmnet] *",
   "language": "python",
   "name": "conda-env-glmnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
